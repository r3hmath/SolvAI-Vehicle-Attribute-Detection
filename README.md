Vehicle Attribute Identification System

This project is an **AI-powered Vehicle Attribute Detection System** built using **YOLOv8**.  
It identifies vehicles, license plates, and brand logos from images or live video feeds â€” and provides per-vehicle insights like:
- Lane position (Left / Center / Right)
- Plate presence (`Yes` / `No`)
- Vehicle direction (`Incoming` / `Outgoing`)
- Real-time statistics on total vehicles, with/without plates, etc.

The system combines **Ultralytics YOLOv8** for detection with a **FastAPI backend** for inference and a **Streamlit** dashboard for visualization.

---

## ğŸ“ Project Structure

vehicle_attribute_identification/
â”‚
â”œâ”€â”€ api/
â”‚ â”œâ”€â”€ model.py # YOLOv8 model loading and inference logic
â”‚ â”œâ”€â”€ main.py # FastAPI app exposing /predict endpoint
â”‚ â”œâ”€â”€ outputs/ # Annotated result images are saved here
â”‚
â”œâ”€â”€ streamlit_app.py # Streamlit frontend UI
â”œâ”€â”€ requirements.txt # All dependencies
â”œâ”€â”€ data.yaml # YOLO dataset configuration file
â”œâ”€â”€ yolov8_vehicle_model/ # Trained YOLOv8 model weights
â”‚ â””â”€â”€ best.pt
â”œâ”€â”€ README.md # This file
â””â”€â”€ ...


---

## ğŸ§  Model Overview

- **Base Model:** YOLOv8 (fine-tuned)
- **Trained on:** Custom dataset of vehicles and license plates
- **Classes:** 14 total

```yaml
nc: 14
names:
  [ 'truck', 'license_plate', 'logo', 'car', 'bike', 'bus',
    'nissan', 'toyota', 'isuzu', 'mitsubishi', 'proton',
    'mazda', 'mercedes', 'honda' ]
âš™ï¸ Installation
Clone the repository


git clone https://github.com/<your_username>/vehicle-attribute-identification.git
cd vehicle-attribute-identification
Create a virtual environment


python -m venv venv
source venv/bin/activate     # on Linux/Mac
venv\Scripts\activate        # on Windows
Install dependencies

pip install -r requirements.txt
Set up model path
Make sure MODEL_PATH in api/model.py points to your trained YOLOv8 weights:

python
Copy code
MODEL_PATH = "path/to/yolov8_vehicle_model/weights/best.pt"
ğŸš€ Running the System
1ï¸âƒ£ Start the FastAPI Backend
bash
Copy code
uvicorn api.main:app --reload
The API will be live at: http://127.0.0.1:8000

Test it via Swagger UI: http://127.0.0.1:8000/docs

/predict Endpoint
Request:

bash
Copy code
POST /predict
Content-Type: multipart/form-data
Body:

file: image file (jpg/png)

Response Example:

json
Copy code
{
  "summary": {
    "timestamp": "2025-10-24 22:09:15",
    "vehicle_count": 4,
    "vehicles_with_plate": 2,
    "vehicles_without_plate": 2,
    "incoming": 1,
    "outgoing": 3,
    "detections": [
      {
        "class": "car",
        "conf": 0.98,
        "bbox": [234, 115, 580, 400],
        "plate_status": "Yes",
        "lane": "Center",
        "direction": "Incoming"
      }
    ]
  },
  "annotated_image_base64": "<base64_string>"
}
2ï¸âƒ£ Run the Streamlit Dashboard
bash
Copy code
streamlit run streamlit_app.py
Upload any image to visualize detections.

The dashboard displays:

Annotated image with bounding boxes.

Real-time stats (vehicles, plates, direction, lanes).

Option to download annotated results.

ğŸ§© Key Features
âœ… Color-preserving inference â€” no grayscale conversion
âœ… Per-vehicle plate detection â€” clearly marked â€œPlate: Yes/Noâ€
âœ… Lane estimation â€” Left / Center / Right
âœ… Direction tagging â€” Incoming / Outgoing
âœ… Top-bar summary â€” instant vehicle statistics
âœ… Robust plateâ€“vehicle matching using IoU + centroid logic
âœ… Configurable thresholds (CONF_THR, IOU_ASSOC_THRESH) in model.py
âœ… Output to both file and base64 for web integration

ğŸ“Š Example Output
Feature	Description
ğŸŸ© Green Boxes	Vehicles (Incoming)
ğŸŸ¥ Red Boxes	Vehicles (Outgoing)
ğŸŸ¨ Yellow Boxes	License Plates
ğŸŸ§ Orange Label	Plate Status
ğŸ•¹ï¸ Header	Stats: Vehicle count, Plates, Direction summary

ğŸ§ª Improving Model Accuracy
If the model performs poorly on new web images:

Use Transfer Learning: fine-tune from yolov8m.pt or yolov8l.pt.

Increase Resolution: train and infer with imgsz=1024.

Add Augmentations: flips, color jitter, blur, mosaic.

Evaluate with TTA: use augment=True during inference.

Recommended command:

yolo detect train model=yolov8m.pt data=path/to/data.yaml epochs=200 imgsz=1024 batch=8 augment=True
ğŸ§° Tech Stack
Component	Tool / Library
Object Detection	Ultralytics YOLOv8
Backend API	FastAPI
Frontend UI	Streamlit
Image Handling	OpenCV, NumPy
Language	Python 3.10+

ğŸ§‘â€ğŸ’» Developer Notes
All inference results (annotated images) are saved under api/outputs/.

Default confidence threshold is 0.25; tweak for sensitivity.

Direction estimation is heuristic â€” for video tracking, integrate model.track(persist=True).

ğŸ§¾ License
This project is released under the MIT License.
Youâ€™re free to use, modify, and distribute â€” with attribution.

ğŸ“¬ Contact
For issues, improvements, or collaboration, open an issue or contact the developer:

Author: [Your Name]
Email: your_email@example.com
GitHub: https://github.com/<your_username>

yaml
